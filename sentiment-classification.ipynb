{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Goal of the project**","metadata":{}},{"cell_type":"markdown","source":"In this project, we try to predict the positive (label 1) or negative (label 0) sentiment of the sentence.","metadata":{}},{"cell_type":"markdown","source":"**Load the packages**","metadata":{}},{"cell_type":"code","source":"# Importing libraries\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-01T14:52:41.034921Z","iopub.execute_input":"2022-09-01T14:52:41.035343Z","iopub.status.idle":"2022-09-01T14:52:41.041161Z","shell.execute_reply.started":"2022-09-01T14:52:41.035310Z","shell.execute_reply":"2022-09-01T14:52:41.039735Z"},"trusted":true},"execution_count":749,"outputs":[]},{"cell_type":"markdown","source":"**Load the data**","metadata":{}},{"cell_type":"markdown","source":"For this project I’ve used the [UCI Sentiment Labelled Sentences Data Set](https://www.kaggle.com/datasets/marklvl/sentiment-labelled-sentences-data-set).\n\nThe dataset was first covered in a paper by Kotzias, Denil, De Freitas, and Smyth in 2015, who compared three approaches, including logistic regression w/ bow, logistic regression w/ embeddings, and gicf w/ embeddings, and managed to achieve an impressive accuracy score of 0.882. Let’s see how close we can get to their best score.\n","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('../input/sentiment-labelled-sentences-data-set/sentiment labelled sentences/amazon_cells_labelled.txt', delimiter = '\\t', header = None, names = ['text', 'label'])","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:41.085934Z","iopub.execute_input":"2022-09-01T14:52:41.086362Z","iopub.status.idle":"2022-09-01T14:52:41.099019Z","shell.execute_reply.started":"2022-09-01T14:52:41.086320Z","shell.execute_reply":"2022-09-01T14:52:41.097601Z"},"trusted":true},"execution_count":750,"outputs":[]},{"cell_type":"code","source":"# Rename Pandas columns to lower case\ndf.columns = df.columns.str.lower()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:41.101047Z","iopub.execute_input":"2022-09-01T14:52:41.101393Z","iopub.status.idle":"2022-09-01T14:52:41.107588Z","shell.execute_reply.started":"2022-09-01T14:52:41.101361Z","shell.execute_reply":"2022-09-01T14:52:41.106289Z"},"trusted":true},"execution_count":751,"outputs":[]},{"cell_type":"code","source":"# Examine the data\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:41.217833Z","iopub.execute_input":"2022-09-01T14:52:41.218256Z","iopub.status.idle":"2022-09-01T14:52:41.229638Z","shell.execute_reply.started":"2022-09-01T14:52:41.218223Z","shell.execute_reply":"2022-09-01T14:52:41.228329Z"},"trusted":true},"execution_count":752,"outputs":[{"execution_count":752,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  So there is no way for me to plug it in here i...      0\n1                        Good case, Excellent value.      1\n2                             Great for the jawbone.      1\n3  Tied to charger for conversations lasting more...      0\n4                                  The mic is great.      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>So there is no way for me to plug it in here i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Good case, Excellent value.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Great for the jawbone.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tied to charger for conversations lasting more...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The mic is great.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Overview of all variables, their datatypes\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:41.312450Z","iopub.execute_input":"2022-09-01T14:52:41.313083Z","iopub.status.idle":"2022-09-01T14:52:41.328313Z","shell.execute_reply.started":"2022-09-01T14:52:41.313027Z","shell.execute_reply":"2022-09-01T14:52:41.326929Z"},"trusted":true},"execution_count":753,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    1000 non-null   object\n 1   label   1000 non-null   int64 \ndtypes: int64(1), object(1)\nmemory usage: 15.8+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Examine the target variable**","metadata":{}},{"cell_type":"markdown","source":"If we run df['label'].value_counts( ) we’ll notice that we have 500 items in the positive class and 500 in the negative class, so things are perfectly balanced.","metadata":{}},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:41.449546Z","iopub.execute_input":"2022-09-01T14:52:41.450850Z","iopub.status.idle":"2022-09-01T14:52:41.460516Z","shell.execute_reply.started":"2022-09-01T14:52:41.450793Z","shell.execute_reply":"2022-09-01T14:52:41.459162Z"},"trusted":true},"execution_count":754,"outputs":[{"execution_count":754,"output_type":"execute_result","data":{"text/plain":"0    500\n1    500\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"**Feature engineering**","metadata":{}},{"cell_type":"markdown","source":"Next we’ll create some features.","metadata":{}},{"cell_type":"code","source":"df['word_count'] = df['text'].apply(lambda x: len(str(x).split(' ')))","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:41.486129Z","iopub.execute_input":"2022-09-01T14:52:41.486522Z","iopub.status.idle":"2022-09-01T14:52:41.496666Z","shell.execute_reply.started":"2022-09-01T14:52:41.486489Z","shell.execute_reply":"2022-09-01T14:52:41.494938Z"},"trusted":true},"execution_count":755,"outputs":[]},{"cell_type":"code","source":"df['sentence_count'] = df['text'].apply(lambda x: len(str(x).split('.')))","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:41.528267Z","iopub.execute_input":"2022-09-01T14:52:41.528709Z","iopub.status.idle":"2022-09-01T14:52:41.538364Z","shell.execute_reply.started":"2022-09-01T14:52:41.528671Z","shell.execute_reply":"2022-09-01T14:52:41.536911Z"},"trusted":true},"execution_count":756,"outputs":[]},{"cell_type":"code","source":"from nltk.sentiment.vader import SentimentIntensityAnalyzer","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:41.672958Z","iopub.execute_input":"2022-09-01T14:52:41.673388Z","iopub.status.idle":"2022-09-01T14:52:41.678810Z","shell.execute_reply.started":"2022-09-01T14:52:41.673353Z","shell.execute_reply":"2022-09-01T14:52:41.677795Z"},"trusted":true},"execution_count":757,"outputs":[]},{"cell_type":"code","source":"df['polarity_score'] = df['text'].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x)['compound'])","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:41.731250Z","iopub.execute_input":"2022-09-01T14:52:41.731786Z","iopub.status.idle":"2022-09-01T14:52:49.770234Z","shell.execute_reply.started":"2022-09-01T14:52:41.731745Z","shell.execute_reply":"2022-09-01T14:52:49.769016Z"},"trusted":true},"execution_count":758,"outputs":[]},{"cell_type":"markdown","source":"**Preprocess the data**","metadata":{}},{"cell_type":"markdown","source":"We will need to preprocess our text to remove misleading junk and noise in order to get the best results from our model.","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nimport unicodedata\nfrom nltk.tokenize.toktok import ToktokTokenizer\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.772173Z","iopub.execute_input":"2022-09-01T14:52:49.772596Z","iopub.status.idle":"2022-09-01T14:52:49.778361Z","shell.execute_reply.started":"2022-09-01T14:52:49.772526Z","shell.execute_reply":"2022-09-01T14:52:49.777082Z"},"trusted":true},"execution_count":759,"outputs":[]},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.781878Z","iopub.execute_input":"2022-09-01T14:52:49.782676Z","iopub.status.idle":"2022-09-01T14:52:49.793729Z","shell.execute_reply.started":"2022-09-01T14:52:49.782626Z","shell.execute_reply":"2022-09-01T14:52:49.792672Z"},"trusted":true},"execution_count":760,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":760,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.796186Z","iopub.execute_input":"2022-09-01T14:52:49.796616Z","iopub.status.idle":"2022-09-01T14:52:49.807483Z","shell.execute_reply.started":"2022-09-01T14:52:49.796547Z","shell.execute_reply":"2022-09-01T14:52:49.806376Z"},"trusted":true},"execution_count":761,"outputs":[]},{"cell_type":"code","source":"def text_cleaning(text_data):\n\n  # Remove accented characters\n  text_data = unicodedata.normalize('NFKD', text_data).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n\n  # Case conversion\n  text_data = text_data.lower()\n\n  # Remove special characters\n  text_data = re.sub(r\"[^a-zA-Z]+\", ' ', text_data)\n\n  # Text as string objects\n  text_data = str(text_data)\n\n  # Tokenization\n  tokenizer = ToktokTokenizer()\n  text_data = tokenizer.tokenize(text_data)\n\n  # Removing stopwords\n  text_data = [item for item in text_data if item not in stop_words]\n  \n  # Convert list of tokens to string data type\n  text_data = ' '.join (text_data)\n\n  return text_data","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.809167Z","iopub.execute_input":"2022-09-01T14:52:49.809921Z","iopub.status.idle":"2022-09-01T14:52:49.818212Z","shell.execute_reply.started":"2022-09-01T14:52:49.809872Z","shell.execute_reply":"2022-09-01T14:52:49.817255Z"},"trusted":true},"execution_count":762,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['text'].apply(text_cleaning)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.819404Z","iopub.execute_input":"2022-09-01T14:52:49.819975Z","iopub.status.idle":"2022-09-01T14:52:49.880714Z","shell.execute_reply.started":"2022-09-01T14:52:49.819941Z","shell.execute_reply":"2022-09-01T14:52:49.879257Z"},"trusted":true},"execution_count":763,"outputs":[]},{"cell_type":"markdown","source":"**Create training and test data**","metadata":{}},{"cell_type":"markdown","source":"To start the modeling process, we’ll assign the text column to our X feature set and the label column to our target variable y. We’ll then use the scikit-learn train_test_split( ) function to divide this into a training and test set, with 20% of the data being held back for testing.","metadata":{}},{"cell_type":"code","source":"X = df.drop('label', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.882344Z","iopub.execute_input":"2022-09-01T14:52:49.883029Z","iopub.status.idle":"2022-09-01T14:52:49.889536Z","shell.execute_reply.started":"2022-09-01T14:52:49.882990Z","shell.execute_reply":"2022-09-01T14:52:49.888539Z"},"trusted":true},"execution_count":764,"outputs":[]},{"cell_type":"code","source":"y = df['label']","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.890964Z","iopub.execute_input":"2022-09-01T14:52:49.891892Z","iopub.status.idle":"2022-09-01T14:52:49.901328Z","shell.execute_reply.started":"2022-09-01T14:52:49.891846Z","shell.execute_reply":"2022-09-01T14:52:49.900048Z"},"trusted":true},"execution_count":765,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.902971Z","iopub.execute_input":"2022-09-01T14:52:49.903323Z","iopub.status.idle":"2022-09-01T14:52:49.911783Z","shell.execute_reply.started":"2022-09-01T14:52:49.903291Z","shell.execute_reply":"2022-09-01T14:52:49.910552Z"},"trusted":true},"execution_count":766,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.915234Z","iopub.execute_input":"2022-09-01T14:52:49.915873Z","iopub.status.idle":"2022-09-01T14:52:49.925474Z","shell.execute_reply.started":"2022-09-01T14:52:49.915834Z","shell.execute_reply":"2022-09-01T14:52:49.924634Z"},"trusted":true},"execution_count":767,"outputs":[]},{"cell_type":"markdown","source":"**Create a model pipeline**","metadata":{}},{"cell_type":"markdown","source":"We construct a pipeline that applies a standard scaler to the numerical features, converts the text column into numerical and then fits a classifier.","metadata":{}},{"cell_type":"code","source":"import time\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.926622Z","iopub.execute_input":"2022-09-01T14:52:49.927337Z","iopub.status.idle":"2022-09-01T14:52:49.941498Z","shell.execute_reply.started":"2022-09-01T14:52:49.927304Z","shell.execute_reply":"2022-09-01T14:52:49.940291Z"},"trusted":true},"execution_count":768,"outputs":[]},{"cell_type":"code","source":"def get_pipeline(X, model):\n\n    \n    numeric_columns = list(X.select_dtypes(exclude = ['object']).columns.values.tolist())\n    numeric_pipeline = Pipeline(steps = [('scaler', StandardScaler())])\n    \n    preprocessor = ColumnTransformer(transformers = [('tfidf', TfidfVectorizer(), 'text'),\n                                                     ('numeric', numeric_pipeline, numeric_columns)], remainder = 'passthrough')\n\n    bundled_pipeline = Pipeline(steps = [('preprocessor', preprocessor),\n                                         ('model', model)])\n    \n    return bundled_pipeline","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.943437Z","iopub.execute_input":"2022-09-01T14:52:49.944112Z","iopub.status.idle":"2022-09-01T14:52:49.952920Z","shell.execute_reply.started":"2022-09-01T14:52:49.943931Z","shell.execute_reply":"2022-09-01T14:52:49.951659Z"},"trusted":true},"execution_count":769,"outputs":[]},{"cell_type":"markdown","source":"**Apply model selection**","metadata":{}},{"cell_type":"markdown","source":"To undertake the model selection step, we first need to create a dictionary containing the name of each model we want to test, and the name of the model class, i.e. XGBClassifier(random_state = 42).\n\nNext we’ll create a Pandas dataframe into which we’ll store the data. Then we’ll loop over each of the models, fit it using the X_train and y_train data, then generate predictions from X_test and calculate the mean accuracy score from 5 rounds of cross-validation. That will give us the accuracy score for the X_test data, plus the average accuracy score for the training data set.","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.954364Z","iopub.execute_input":"2022-09-01T14:52:49.954890Z","iopub.status.idle":"2022-09-01T14:52:49.964156Z","shell.execute_reply.started":"2022-09-01T14:52:49.954842Z","shell.execute_reply":"2022-09-01T14:52:49.963257Z"},"trusted":true},"execution_count":770,"outputs":[]},{"cell_type":"code","source":"def select_model(X, y, pipeline = None):\n\n  classifiers = {}\n  classifiers.update({'XGBClassifier': XGBClassifier(random_state = 42)})\n  classifiers.update({'LGBMClassifier': LGBMClassifier(random_state = 42)})\n  classifiers.update({'DecisionTreeClassifier': DecisionTreeClassifier(random_state = 42)})\n  classifiers.update({'RandomForestClassifier': RandomForestClassifier(random_state = 42)})\n  classifiers.update({'ExtraTreesClassifier': ExtraTreesClassifier(random_state = 42)})\n  classifiers.update({'GradientBoostingClassifier': GradientBoostingClassifier(random_state = 42)})    \n  classifiers.update({'BaggingClassifier': BaggingClassifier(random_state = 42)})\n  classifiers.update({'AdaBoostClassifier': AdaBoostClassifier(random_state = 42)})\n  classifiers.update({'CatBoostClassifier': CatBoostClassifier(silent = True, random_seed = 42)})\n  classifiers.update({'LogisticRegression': LogisticRegression(random_state = 42)})\n  classifiers.update({'BernoulliNB': BernoulliNB()})\n\n  df_models = pd.DataFrame(columns = ['model', 'run_time', 'accuracy_score_cv', 'accuracy_score'])\n\n  for key in classifiers:\n\n      print('*', key)\n\n      start_time = time.time()\n      \n      pipeline = get_pipeline(X_train, classifiers[key])\n\n      cv = cross_val_score(pipeline, X, y, cv = 5, scoring = 'accuracy', n_jobs = -1)\n      \n      pipeline.fit(X_train, y_train)\n      y_pred = pipeline.predict(X_test)\n    \n      row = {'model': key,\n             'run_time': format(round((time.time() - start_time) / 60, 2)),\n             'accuracy_score_cv': cv.mean(),\n             'accuracy_score': accuracy_score(y_test, y_pred)}\n      \n      df_models = df_models.append(row, ignore_index = True)\n\n  df_models = df_models.sort_values(by = 'accuracy_score', ascending = False)\n      \n  return df_models","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.965437Z","iopub.execute_input":"2022-09-01T14:52:49.965999Z","iopub.status.idle":"2022-09-01T14:52:49.979413Z","shell.execute_reply.started":"2022-09-01T14:52:49.965964Z","shell.execute_reply":"2022-09-01T14:52:49.978156Z"},"trusted":true},"execution_count":771,"outputs":[]},{"cell_type":"code","source":"models = select_model(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:52:49.983678Z","iopub.execute_input":"2022-09-01T14:52:49.984061Z","iopub.status.idle":"2022-09-01T14:53:33.371191Z","shell.execute_reply.started":"2022-09-01T14:52:49.984021Z","shell.execute_reply":"2022-09-01T14:53:33.369811Z"},"trusted":true},"execution_count":772,"outputs":[{"name":"stdout","text":"* XGBClassifier\n* LGBMClassifier\n* DecisionTreeClassifier\n* RandomForestClassifier\n* ExtraTreesClassifier\n* GradientBoostingClassifier\n* BaggingClassifier\n* AdaBoostClassifier\n* CatBoostClassifier\n* LogisticRegression\n* BernoulliNB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After 1-2 minutes, the model selection process had completed. This identified that ExtraTreesClassifier was the top performing model, with an accuracy of 86.5%.","metadata":{}},{"cell_type":"code","source":"models.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:53:33.373059Z","iopub.execute_input":"2022-09-01T14:53:33.373714Z","iopub.status.idle":"2022-09-01T14:53:33.388597Z","shell.execute_reply.started":"2022-09-01T14:53:33.373673Z","shell.execute_reply":"2022-09-01T14:53:33.387380Z"},"trusted":true},"execution_count":773,"outputs":[{"execution_count":773,"output_type":"execute_result","data":{"text/plain":"                         model run_time  accuracy_score_cv  accuracy_score\n4         ExtraTreesClassifier     0.02            0.86500           0.865\n3       RandomForestClassifier     0.02            0.85500           0.850\n10                 BernoulliNB      0.0            0.85125           0.845\n0                XGBClassifier     0.03            0.84500           0.835\n5   GradientBoostingClassifier     0.02            0.85625           0.835\n9           LogisticRegression      0.0            0.85500           0.835\n8           CatBoostClassifier      0.6            0.84875           0.830\n1               LGBMClassifier     0.01            0.83500           0.825\n6            BaggingClassifier     0.01            0.85750           0.815\n7           AdaBoostClassifier     0.01            0.83125           0.810","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>run_time</th>\n      <th>accuracy_score_cv</th>\n      <th>accuracy_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>ExtraTreesClassifier</td>\n      <td>0.02</td>\n      <td>0.86500</td>\n      <td>0.865</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RandomForestClassifier</td>\n      <td>0.02</td>\n      <td>0.85500</td>\n      <td>0.850</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>BernoulliNB</td>\n      <td>0.0</td>\n      <td>0.85125</td>\n      <td>0.845</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>XGBClassifier</td>\n      <td>0.03</td>\n      <td>0.84500</td>\n      <td>0.835</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GradientBoostingClassifier</td>\n      <td>0.02</td>\n      <td>0.85625</td>\n      <td>0.835</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LogisticRegression</td>\n      <td>0.0</td>\n      <td>0.85500</td>\n      <td>0.835</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>CatBoostClassifier</td>\n      <td>0.6</td>\n      <td>0.84875</td>\n      <td>0.830</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LGBMClassifier</td>\n      <td>0.01</td>\n      <td>0.83500</td>\n      <td>0.825</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>BaggingClassifier</td>\n      <td>0.01</td>\n      <td>0.85750</td>\n      <td>0.815</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>AdaBoostClassifier</td>\n      <td>0.01</td>\n      <td>0.83125</td>\n      <td>0.810</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Evaluate model performance**","metadata":{}},{"cell_type":"code","source":"bundled_pipeline = get_pipeline(X_train, ExtraTreesClassifier(random_state = 42))\nbundled_pipeline.fit(X_train, y_train)\ny_pred = bundled_pipeline.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:53:33.390414Z","iopub.execute_input":"2022-09-01T14:53:33.391227Z","iopub.status.idle":"2022-09-01T14:53:33.846121Z","shell.execute_reply.started":"2022-09-01T14:53:33.391171Z","shell.execute_reply":"2022-09-01T14:53:33.845152Z"},"trusted":true},"execution_count":774,"outputs":[]},{"cell_type":"markdown","source":"Another useful metric for evaluating a classification model is the classification report, which can be accessed via the classification_report( ) function.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:53:33.847481Z","iopub.execute_input":"2022-09-01T14:53:33.847844Z","iopub.status.idle":"2022-09-01T14:53:33.853676Z","shell.execute_reply.started":"2022-09-01T14:53:33.847811Z","shell.execute_reply":"2022-09-01T14:53:33.852258Z"},"trusted":true},"execution_count":775,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-09-01T14:53:33.855574Z","iopub.execute_input":"2022-09-01T14:53:33.855941Z","iopub.status.idle":"2022-09-01T14:53:33.875138Z","shell.execute_reply.started":"2022-09-01T14:53:33.855908Z","shell.execute_reply":"2022-09-01T14:53:33.873550Z"},"trusted":true},"execution_count":776,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86        93\n           1       0.90      0.84      0.87       107\n\n    accuracy                           0.86       200\n   macro avg       0.86      0.87      0.86       200\nweighted avg       0.87      0.86      0.87       200\n\n","output_type":"stream"}]}]}